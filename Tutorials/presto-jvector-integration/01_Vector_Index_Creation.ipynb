{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df3c790b",
   "metadata": {},
   "source": [
    "# <b><center>Vector Index Creation</center></b>\n",
    "\n",
    "  \n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Connect to Presto/Iceberg\n",
    "2. Generate vector embeddings from text data\n",
    "3. Store embeddings in an Iceberg table\n",
    "4. Create a vector index for fast similarity search\n",
    "\n",
    "**Prerequisites:**\n",
    "\n",
    "- Presto server running on local/vm/cpd/saas\n",
    "- Iceberg catalog should be created and the bucket needs to be associated\n",
    "- The test data must be in CSV format and accessible either from the working directory or via a specified file path\n",
    "- To install required python packages run \"pip install -r requirements.txt\"\n",
    "\n",
    "For full breakdown please refer to the [README_NOTEBOOKS.md](README_NOTEBOOKS.md)   \n",
    "\n",
    "\n",
    "**Expected Output:**\n",
    "- Generated embeddings are stored in iceberg table.\n",
    "- Vector index created for fast retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf7040c",
   "metadata": {},
   "source": [
    "#### <b> Configuration & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872d2f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === CONFIGURATION ===\n",
    "# Presto Connection\n",
    "HOST = '' #host engine address\n",
    "PORT = 8080\n",
    "# Authentication (Optional)\n",
    "HTTP_SCHEME = 'http'  # or 'https'\n",
    "USER = '' #host instance username\n",
    "PASSWORD = ''  # Leave empty if not using auth\n",
    "DISABLE_SSL_VERIFICATION = True  # Only for dev with self-signed certs\n",
    "CATALOG = '' # Presto catalog name\n",
    "SCHEMA = '' # Presto schema name\n",
    "S3_LOCATION = f\"s3a://<bucketname>/{SCHEMA}\"\n",
    "TABLE = ''  # Presto table name\n",
    "# Table Schema Configuration (CUSTOMIZABLE)\n",
    "TEXT_COLUMN = ''  # Name for text column in table\n",
    "EMBEDDING_COLUMN = ''  # Name for embedding column in table\n",
    "\n",
    "# Data Processing\n",
    "CSV_FILE = \"path/to/csv\" # Path to the csv file\n",
    "SOURCE_COLUMN = ''  # CHANGE THIS to the column you want to embed\n",
    "\n",
    "OUTPUT_FILE = \"embeddings.csv\"\n",
    "SQL_FILE = \"inserts.sql\"\n",
    "MODEL_NAME = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "NUM_ROWS = 100\n",
    "BATCH_SIZE = 15  # Number of rows to process at a time. Recommended to keep this value below 15 for optimal performance/stability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7067d7d9",
   "metadata": {},
   "source": [
    "#### Initializing helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedfabbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "import prestodb\n",
    "from prestodb.exceptions import PrestoUserError\n",
    "from typing import Dict, Any, Tuple, List, Optional, cast\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import re\n",
    "import textwrap\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "\n",
    "# === HELPER FUNCTIONS ===\n",
    "def get_presto_connection(\n",
    "    host: str = HOST,\n",
    "    port: int = PORT,\n",
    "    user: str = USER,\n",
    "    catalog: str = CATALOG,\n",
    "    schema: str = SCHEMA,\n",
    "    http_scheme: str = HTTP_SCHEME,\n",
    "    principal_id: str = USER,\n",
    "    password: str = PASSWORD,\n",
    "    disable_ssl_verification: bool = DISABLE_SSL_VERIFICATION\n",
    ") -> prestodb.dbapi.Connection:\n",
    "    \"\"\"Create Presto connection with optional basic authentication and SSL verification control\"\"\"\n",
    "    try:\n",
    "        # Build connection parameters\n",
    "        conn_params = {\n",
    "            'host': host,\n",
    "            'port': port,\n",
    "            'user': user,\n",
    "            'catalog': catalog,\n",
    "            'schema': schema,\n",
    "            'http_scheme': http_scheme,\n",
    "        }\n",
    "        \n",
    "        # Add basic authentication if credentials provided\n",
    "        if user and password:\n",
    "            conn_params['auth'] = prestodb.auth.BasicAuthentication(user, password)\n",
    "        \n",
    "        conn = prestodb.dbapi.connect(**conn_params)\n",
    "        \n",
    "        # Disable SSL verification if requested (for self-signed certificates)\n",
    "        if disable_ssl_verification and http_scheme == 'https':\n",
    "            conn._http_session.verify = False\n",
    "        \n",
    "        print(f\"Connected to {http_scheme}://{host}:{port}\")\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        raise PrestoUserError(f\"Connection Error: {e}\")\n",
    "\n",
    "def execute_query(conn: prestodb.dbapi.Connection, sql: str, fetch: bool = False):\n",
    "    cursor = None\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(sql)\n",
    "        if fetch:\n",
    "            return cursor.fetchall(), cursor.description\n",
    "        return None, None\n",
    "    except prestodb.exceptions.PrestoUserError as e:\n",
    "        print(f\"Query Failed: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "\n",
    "print(\" Configuration and helper functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76764464",
   "metadata": {},
   "source": [
    "#### <b> Test Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5445d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = None\n",
    "try:\n",
    "    conn = get_presto_connection()\n",
    "    results, _ = execute_query(conn, \"SELECT 1\", fetch=True)\n",
    "    \n",
    "    if results:\n",
    "        print(\"Connection test PASSED\")\n",
    "        print(f\"Connected to catalog: {CATALOG}, schema: {SCHEMA}\")\n",
    "    else:\n",
    "        print(\" Connection test returned unexpected result\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Connection test FAILED: {e}\")\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72b600d",
   "metadata": {},
   "source": [
    "#### <b> Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ef4594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "if not os.path.exists(CSV_FILE):\n",
    "    raise FileNotFoundError(f\"Error: '{CSV_FILE}' not found\")\n",
    "\n",
    "df: pd.DataFrame = pd.read_csv(CSV_FILE, nrows=NUM_ROWS)\n",
    "\n",
    "# Use single column from CSV\n",
    "df = cast(pd.DataFrame, df[[SOURCE_COLUMN]].dropna().reset_index(drop=True))\n",
    "df[TEXT_COLUMN] = df[SOURCE_COLUMN].astype(str)\n",
    "df['row_id'] = df.index + 1\n",
    "df = cast(pd.DataFrame, df[['row_id', TEXT_COLUMN]])\n",
    "\n",
    "\n",
    "# Generate embeddings\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "print(f\"✓ Model '{MODEL_NAME}' loaded\")\n",
    "print(f\"  Generating embeddings...\")\n",
    "\n",
    "# Generate embeddings\n",
    "text_list = cast(List[str], df[TEXT_COLUMN].tolist())\n",
    "embeddings = model.encode(\n",
    "    text_list,\n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "embedding_dim = len(embeddings[0])\n",
    "print(f\"✓ Generated {len(embeddings)} embeddings (dimension: {embedding_dim})\")\n",
    "\n",
    "# Save to CSV\n",
    "df[EMBEDDING_COLUMN] = [emb.tolist() for emb in embeddings]\n",
    "df.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"✓ Saved embeddings to '{OUTPUT_FILE}'\")\n",
    "\n",
    "# Display sample\n",
    "print(f\"\\nSample data (first 3 rows):\")\n",
    "print(cast(pd.DataFrame, df[['row_id', TEXT_COLUMN]].head(3)).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dc849b",
   "metadata": {},
   "source": [
    "#### <b> Create schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef19e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = get_presto_connection()\n",
    "\n",
    "create_schema_sql = f\"\"\"\n",
    "            CREATE SCHEMA IF NOT EXISTS {CATALOG}.{SCHEMA}\n",
    "            WITH (\n",
    "                location = '{S3_LOCATION}'\n",
    "            )\n",
    "        \"\"\"\n",
    "\n",
    "execute_query(conn, create_schema_sql, fetch=False)\n",
    "    \n",
    "print(f\" SUCCESS: Schema '{SCHEMA}' created or already exists in '{CATALOG}'.\")\n",
    "print(f\" Location: {S3_LOCATION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b43666f",
   "metadata": {},
   "source": [
    "#### <b> Create Iceberg Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b65cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_TABLE_NAME = f\"{CATALOG}.{SCHEMA}.{TABLE}\"\n",
    "\n",
    "CREATE_TABLE_DDL = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {FULL_TABLE_NAME} (\n",
    "    row_id      BIGINT,\n",
    "    {TEXT_COLUMN}     VARCHAR,\n",
    "    {EMBEDDING_COLUMN}   ARRAY(REAL)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "conn = None\n",
    "try:\n",
    "    conn = get_presto_connection()\n",
    "    \n",
    "    # Create table\n",
    "    print(f\"Creating table: {FULL_TABLE_NAME}\")\n",
    "    execute_query(conn, CREATE_TABLE_DDL, fetch=False)\n",
    "    print(\"Table created successfully\")\n",
    "    \n",
    "    # Validate with DESCRIBE\n",
    "    describe_results, description = execute_query(\n",
    "        conn, f\"DESCRIBE {FULL_TABLE_NAME}\", fetch=True\n",
    "    )\n",
    "    \n",
    "    if describe_results:\n",
    "        print(f\"\\nTable Schema:\")\n",
    "        print(\"-\" * 50)\n",
    "        for row in describe_results:\n",
    "            print(f\"  {row[0]:<15} {row[1]}\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Table validated with {len(describe_results)} columns\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Table creation failed: {e}\")\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7761c75",
   "metadata": {},
   "source": [
    "#### <b> Generate & Execute Inserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b0896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SQL inserts\n",
    "print(f\"Generating batch INSERT statements (batch size: {BATCH_SIZE})...\")\n",
    "inserts = []\n",
    "batch = []\n",
    "\n",
    "with open(OUTPUT_FILE, newline='', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    fieldnames = reader.fieldnames\n",
    "    \n",
    "    # Handle BOM if present\n",
    "    if fieldnames and fieldnames[0].startswith('\\ufeff'):\n",
    "        fieldnames_list = list(fieldnames)\n",
    "        fieldnames_list[0] = fieldnames_list[0].lstrip('\\ufeff')\n",
    "        reader.fieldnames = fieldnames\n",
    "        reader.fieldnames = fieldnames_list\n",
    "    \n",
    "    for row in reader:\n",
    "        row_id = row['row_id']\n",
    "        # Enhanced escaping for SQL injection protection\n",
    "        comment = row[TEXT_COLUMN].replace(\"'\", \"''\").replace(\"\\\\\", \"\\\\\\\\\")\n",
    "        embedding_list = json.loads(row[EMBEDDING_COLUMN])\n",
    "        embedding_array = \"ARRAY[\" + \",\".join(map(str, embedding_list)) + \"]\"\n",
    "        \n",
    "        batch.append(f\"({row_id}, '{comment}', CAST({embedding_array} AS ARRAY(REAL)))\")\n",
    "        \n",
    "        if len(batch) >= BATCH_SIZE:\n",
    "            inserts.append(\n",
    "                f\"INSERT INTO {CATALOG}.{SCHEMA}.{TABLE} (row_id, {TEXT_COLUMN}, {EMBEDDING_COLUMN}) \"\n",
    "                f\"VALUES {', '.join(batch)}\"\n",
    "            )\n",
    "            batch = []\n",
    "    \n",
    "    if batch:\n",
    "        inserts.append(\n",
    "            f\"INSERT INTO {CATALOG}.{SCHEMA}.{TABLE} (row_id, {TEXT_COLUMN}, {EMBEDDING_COLUMN}) \"\n",
    "            f\"VALUES {', '.join(batch)}\"\n",
    "        )\n",
    "\n",
    "# Save SQL file\n",
    "with open(SQL_FILE, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"\\n\".join(inserts))\n",
    "\n",
    "print(f\"Generated {len(inserts)} INSERT statements\")\n",
    "print(f\"Saved to '{SQL_FILE}'\")\n",
    "\n",
    "# Execute inserts\n",
    "print(f\"\\nExecuting INSERT statements...\")\n",
    "conn = None\n",
    "cursor = None\n",
    "try:\n",
    "    conn = get_presto_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    for i, statement in enumerate(inserts, 1):\n",
    "        print(f\"  Executing batch {i}/{len(inserts)}...\", end='\\r')\n",
    "        cursor.execute(statement)\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"\\nAll {len(inserts)} batches executed successfully\")\n",
    "    \n",
    "    # Verify row count\n",
    "    count_results, _ = execute_query(\n",
    "        conn, f\"SELECT COUNT(*) FROM {CATALOG}.{SCHEMA}.{TABLE}\", fetch=True\n",
    "    )\n",
    "    if count_results:\n",
    "        print(f\"Table now contains {count_results[0][0]} rows\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nInsert execution failed: {e}\")\n",
    "    if conn:\n",
    "        conn.rollback()\n",
    "finally:\n",
    "    if cursor is not None:  \n",
    "        cursor.close()\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1b099f",
   "metadata": {},
   "source": [
    "#### <b> Create Vector Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f5cb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_COMMAND = f\"CALL {CATALOG}.system.CREATE_VEC_INDEX('{CATALOG}.{SCHEMA}.{TABLE}.{EMBEDDING_COLUMN}')\"\n",
    "\n",
    "conn = None\n",
    "try:\n",
    "    conn = get_presto_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    print(f\"Creating vector index on {TABLE}.embedding...\")\n",
    "    cursor.execute(INDEX_COMMAND)\n",
    "    conn.commit()\n",
    "    \n",
    "    print(\" Vector index created successfully\")\n",
    "    print(\" Table is now ready for similarity search\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" Index creation failed: {e}\")\n",
    "finally:\n",
    "    if cursor is not None:\n",
    "        cursor.close()\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
